---
title: "Linear Models Project"
author: "Mengyang, Ayisha, Seeth, Sepideh"
date: "`r Sys.Date()`"
output: html_document
---
```{r}
pkg_list <- c("glmnet", "boot", "MASS", "ggplot2", "openxlsx", "rlang", "readxl", "dplyr", "cvTools", "Matrix", "boot","caret") 
# Install packages if needed
for (pkg in pkg_list) {
  # Try loading the library.
  if (!library(pkg, logical.return = TRUE, character.only = TRUE)) {
    # If the library cannot be loaded, install it; then load.
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}
```



(i)  EDA 
```{r}

Boston_houseprice <- read_excel("/Users/mengyangzhang/Desktop/Boston_houseprice.xlsx")
View(Boston_houseprice)
```

```{r}
dim(Boston_houseprice)
names(Boston_houseprice)
```

```{r}
sum(is.na(Boston_houseprice))
```

```{r}

Boston_houseprice_cleaned <- select(Boston_houseprice, -c(OBS., MEDV, B, LSTAT, TOWN))


```

```{r}

#Boston_houseprice_cleaned
# Generate summary for the dataset
boston_summary <- summary(Boston_houseprice_cleaned)

# View the summary table
print(boston_summary)

```

```{r}
#Boston_houseprice$CHAS_cat <- Boston_houseprice$CHAS
#Boston_houseprice
```

```{r}
# Identify missing values
missing_values <- sapply(Boston_houseprice_cleaned, function(x) sum(is.na(x)))
missing_values
```


```{r}


# Assuming Boston_houseprice is your dataset and CMEDV is the response variable
p <- ggplot(Boston_houseprice, aes(y = CMEDV)) + 
  geom_boxplot() + 
  labs(title = "Boxplot of CMEDV", y = "Median Value of Homes (in $1000s)")
print(p)

```

In economic and housing data, outliers often hold valuable insights and reflect genuine variability, like premium properties or unusual market segments. They are integral to the data's authenticity and can be critical for robust modeling. Thus, these outliers are not dismissed carelessly, preserving the dataset's real-world complexity.

```{r}
# Statistical method for identifying outliers using IQR
# Identify numeric columns
numeric_columns <- sapply(Boston_houseprice_cleaned, is.numeric)

# Calculate IQR for each numeric column, excluding NA values
IQR_values <- apply(Boston_houseprice_cleaned[, numeric_columns], 2, IQR, na.rm = TRUE)
IQR_values


# Detecting outliers
outliers <- lapply(Boston_houseprice_cleaned, function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR_x <- IQR(x, na.rm = TRUE)
  return(x[x < (Q1 - 1.5 * IQR_x) | x > (Q3 + 1.5 * IQR_x)])
})
```





Since the outliers removes much of the data which are required we are not removing 








# (ii) Variable Selection 

```{r}
Boston_houseprice_scaled <- scale(Boston_houseprice_cleaned)
#random sampling
index <- sample(nrow(Boston_houseprice_scaled),nrow(Boston_houseprice_scaled)*0.80)
boston_train <- Boston_houseprice_scaled[index,]
boston_test <- Boston_houseprice_scaled[-index,]
```





```{r}
library(ggcorrplot)
corr <- round(cor(boston_train), 1)
ggcorrplot(corr, hc.order = TRUE, type = "lower", lab = TRUE,
   outline.col = "white",
   ggtheme = ggplot2::theme_gray,
   colors = c("#6D9EC1", "white", "#E46726"))
```



```{r}
boston_train <- as.data.frame(boston_train)
# Forward variable selection
Model_null <- lm(CMEDV~1, data = boston_train)
Model_full <- lm(CMEDV~., data = boston_train)

Model_step<- step(Model_null, scope=list(lower=Model_null, upper=Model_full), direction='both', trace=FALSE)
summary(Model_step)


```

```{r}
Model_step.BIC <- step(Model_step, k=log(nrow(boston_train))) 
```




```{r}
# Assuming 'Boston_houseprice_cleaned' is your cleaned dataset and 'index' is correctly defined somewhere in your code.
set.seed(1234)
# Standardizing the data excluding the target variable 'CMEDV'
Boston_standardised <- scale(dplyr::select(Boston_houseprice_cleaned, -CMEDV))
# Creating training and testing sets
X_train <- as.matrix(Boston_standardised)[index, ]
X_test  <- as.matrix(Boston_standardised)[-index, ]
Y_train <- Boston_houseprice_cleaned$CMEDV[index]
Y_test  <- Boston_houseprice_cleaned$CMEDV[-index]

# Finding the optimal lambda with 10-fold cross-validation

cv.lasso <- cv.glmnet(x = X_train, y = Y_train, alpha = 1, family = "gaussian")

# Plotting the cross-validation curve to find the optimal lambda
plot(cv.lasso)


```




```{r}
#fit model
Model_lasso<- glmnet(x=X_train, y=Y_train, family = "gaussian", alpha = 1)
plot(Model_lasso, xvar = "lambda")

```

```{r}
Cross_validation_lasso<- cv.glmnet(x=X_train, y=Y_train, family = "gaussian", alpha = 1, nfolds = 10)
plot(Cross_validation_lasso)

```

```{r}
lamda_min<-Cross_validation_lasso$lambda.min
lamda_lse<-Cross_validation_lasso$lambda.1se
```



```{r}
coef(Model_lasso, s=lamda_min)

```


```{r}
coef(Model_lasso, s=lamda_lse)
```

```{r}
par(mfrow=c(2,2))
plot(Model_step)
```

```{r}
par(mfrow=c(2,2))
plot(Model_lasso)
```



(iii) Multiple regression analysis 


```{r}
Model_multiple <- lm(CMEDV ~ LON+CRIM+CHAS+NOX+RM+AGE+TAX+PTRATIO, data = Boston_houseprice_cleaned)
summary(Model_multiple)
```

```{r}
Model_multiple_final <- lm(CMEDV ~ LON+CRIM+CHAS+NOX+RM+PTRATIO, data = Boston_houseprice_cleaned)
summary(Model_multiple_final)
```

(iv)
```{r}
plot(Model_multiple_final)
```





(v)
```{r}
# Estimate confidence intervals
conf_int <- confint(Model_multiple_final, level=0.95)
print(conf_int)


#stepwise_model
model_vars <- names(coef(Model_multiple_final)[-1])
set.seed(123) 
k <- 5 # 
n <- nrow(Boston_houseprice_cleaned)
folds <- cut(seq(1,n), breaks=k, labels=FALSE) 

Boston_houseprice_cleaned$CHAS <- as.factor(Boston_houseprice_cleaned$CHAS)

test_errors <- vector('numeric', k)

for(i in 1:k){
 
  testIndexes <- which(folds==i, arr.ind=TRUE)
  testData <- Boston_houseprice_cleaned[testIndexes, ]
  trainData <- Boston_houseprice_cleaned[-testIndexes, ]
  
  # stepwise_model
  formula_str <- paste("CMEDV ~", paste(model_vars, collapse=" + "))
  model_formula <- as.formula(formula_str)
  model <- lm(model_formula, data=trainData)
  
  
  predictions <- predict(model, newdata=testData)
  test_errors[i] <- mean((predictions - testData$CMEDV)^2)
}


mean_test_error <- mean(test_errors)
cat("Mean test error is:", mean_test_error, "\n")
```



```{r}


# k-Fold Cross-Validation
set.seed(17)
cv.error.10=rep(0,10) # 10 degree polynomial

for (i in 1:10){
 glm.fit=glm(Model_step,data=Boston_houseprice_cleaned)
 cv.error.10[i]=cv.glm(Boston_houseprice_cleaned,glm.fit,K=10)$delta[1]
 }
cv.error.10

# Plot the CV errors
par(mfrow=c(1,2))
#degree1=1:10
#plot(degree1, cv.error, type="b", main="LOOCV")

degree2=1:10
plot(degree2, cv.error.10, type="b", main="10-fold CV")
```


